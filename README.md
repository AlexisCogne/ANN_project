# Deep Reinforcement Learning Mini-Project
From Discrete to Continuous Advantage Actor-Critic (A2C) \
Implementation on the Inverted Pendulum environment from OpenAI Gym

# Team
- Riccardo Carpineto (NX-MA2)
- Alexis Cogne (NX-MA2)

# Description of files
- A2C_continuous.py & A2C_continuous.py: files containing the Advantage Actor Critic (A2C) Classes
- agent_showcase.py: file to display the agent balancing the inverted pendulum
- main.ipynb: notebook file to train the 6 agents (discrete, continous and with several steps or workers)
- plotting.ipynb: notebook file to generate all the plots used in the report
- utils.py: file containing all functions used in the code
  
# Preview
<div style="display: flex; flex-direction: row; gap: 10px;">
  <img src="https://github.com/user-attachments/assets/6f63d8aa-1bc1-4ed7-a1f4-f943091a5c85" alt="Met_maps" style="width: 40%;">
  <img src="https://github.com/user-attachments/assets/393e5a05-322e-438f-a9da-5e5dbf1e525f" alt="Hippocampus_relative_concentrations" style="width: 40%;">
</div>

